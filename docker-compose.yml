services:
  backend:
    build:
      context: ./afin-backend
      dockerfile: Dockerfile.test
    container_name: afin-backend
    environment:
      - DATABASE_URL=sqlite:///./afin.db
      # URL сервиса LLM внутри Docker-сети
      - LLM_SERVICE_URL=http://ai-assistant:8000
    ports:
      - "8000:8000"
    volumes:
      - ./afin-backend/storage/afin.db:/app/afin.db
    depends_on:
      - ai-assistant
    restart: unless-stopped

  frontend:
    build:
      context: ./afin-frontend
      dockerfile: Dockerfile
    container_name: afin-frontend
    environment:
      # Фронтенд ходит на /api, nginx внутри контейнера проксирует на backend:8000
      - VITE_API_BASE_URL=/api
    ports:
      - "3000:80"
    depends_on:
      - backend
    restart: unless-stopped

  ai-assistant:
    build:
      context: ./Проект_AI_ассистент_свежий
      dockerfile: Dockerfile
    container_name: ai-assistant
    environment:
      # Модель с Hugging Face Hub (можно указать свою дообученную модель)
      - HF_MODEL_NAME=SpaWn03/fixed-qwen2-1.5b-instruct-business-assistant
      # Если модель приватная, раскомментируйте и укажите токен:
      # - HF_TOKEN=your_huggingface_token_here
      # Внутри сети сервис доступен по http://ai-assistant:8000
    expose:
      - "8000"
    restart: unless-stopped
