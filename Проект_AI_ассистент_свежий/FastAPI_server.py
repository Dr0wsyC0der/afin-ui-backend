from fastapi import FastAPI
from pydantic import BaseModel
import json
import pandas as pd
from model_and_scaler import model, scaler, model_features

from LLM.model_predictor import generate_explanation

import traceback
import logging
logging.basicConfig(level=logging.INFO)

app = FastAPI(title="AI Delay Predictor")

# -----------------------------
# 3Ô∏è‚É£ –û–ø–∏—Å–∞–Ω–∏–µ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
# -----------------------------
class TaskFeatures(BaseModel):
    expected_duration: float
    process_name: str
    role: str
    department: str
    status: str = "active"
    month: int
    weekday: int

class LLMRequest(BaseModel):
    expected_duration: float
    process_name: str
    role: str
    department: str
    status: str = "active"
    month: int | None = None
    weekday: int | None = None
    delay_probability: float
    prediction: str
# -----------------------------
# 4Ô∏è‚É£ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞
# -----------------------------
@app.get("/")
def root():
    return {"message": "API is running", "routes": [r.path for r in app.routes]}

@app.post("/test_json")
def work_json(payload: dict):
    print("‚úÖ –ü–æ–ª—É—á–µ–Ω JSON:", payload)
    return {"received": True, "payload": payload}

@app.post("/predict_delay")
def predict_delay(task: TaskFeatures):
    try:
        # –§–æ—Ä–º–∏—Ä—É–µ–º DataFrame
        df = pd.DataFrame([task.model_dump()])  # ‚úÖ –∑–∞–º–µ–Ω–∏–ª–∏ .dict() –Ω–∞ .model_dump()

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        cat_cols = ["status", "process_name", "role", "department"]
        for c in cat_cols:
            if c in df.columns:
                df[c] = df[c].astype("category")

        # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º —á–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        numeric_cols = [c for c in df.columns if df[c].dtype in ["int64", "float64"]]
        for col in numeric_cols:
            if col not in model_features:
                df.drop(columns=[col], inplace=True, errors="ignore")

        # –¥–æ–±–∞–≤–ª—è–µ–º –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ –æ–±—É—á–∞—é—â–µ–≥–æ –Ω–∞–±–æ—Ä–∞
        for col in model_features:
            if col not in df.columns:
                df[col] = 0

        df = df[model_features]  # –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–µ–º –ø–æ—Ä—è–¥–æ–∫

        # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ (—Ç–æ–ª—å–∫–æ —Ç–µ—Ö –∫–æ–ª–æ–Ω–æ–∫, –Ω–∞ –∫–æ—Ç–æ—Ä—ã—Ö scaler –æ–±—É—á–µ–Ω)
        common_cols = list(set(model_features) & set(scaler.feature_names_in_))
        df[common_cols] = scaler.transform(df[common_cols])

        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        prob = float(model.predict(df)[0])
        label = int(prob > 0.5)

        return {
            "delay_probability": round(prob, 3),
            "prediction": "Delayed" if label == 1 else "On time"
        }
    except Exception as e:
        import traceback
        logging.error("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞:")
        traceback.print_exc()
        return {"error": str(e)}

@app.post("/explain_delay")
def explain_delay(req: LLMRequest):
    try:
        logging.info("üîÑ –ü–æ–ª—É—á–µ–Ω –∑–∞–ø—Ä–æ—Å –Ω–∞ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –∑–∞–¥–µ—Ä–∂–∫–∏")

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º Pydantic –º–æ–¥–µ–ª—å –≤ —Å–ª–æ–≤–∞—Ä—å
        input_data = req.model_dump()

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ —Å –ø–æ–º–æ—â—å—é LLM
        explanation = generate_explanation(input_data)

        logging.info("‚úÖ –û–±—ä—è—Å–Ω–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ")

        return {
            "success": True,
            "explanation": explanation,
            "input_data": input_data
        }

    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è: {str(e)}")
        traceback.print_exc()
        return {
            "success": False,
            "error": str(e),
            "explanation": None
        }


if __name__ == "__main__":
    import uvicorn
    uvicorn.run("FastAPI_server:app", host="0.0.0.0", port=8000, reload=False)
